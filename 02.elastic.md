# Elastic stack

## 개요

### 배경

* 2004년 샤이 배논(Shay Banon)은 Compass 라는 이름의 오픈소스 검색엔진을 개발하였습니다. 
* 2010년 샤이는 Compass를 Elasticsearch라고 이름을 바꾸고 프로젝트를 오픈소스로 공개하였는데, 곧 수많은 검색 개발자들에게 인기를 얻으며 급속도로 성장하기 시작했습니다. 
*  Elasticsearch 프로젝트는 2012년에 창시자 샤이 배논과 함께 스티븐 셔르만(Steven Schuurman), 우리 보네스(Uri Boness) 그리고 아파치 루씬 커미터인 사이먼 윌너(Simon Willnauer) 4인의 멤버에 인해 네델란드 암스텔담에서 처음 회사로 설립.
*  Logstash, Kibana와 함께 사용 되면서 한동안 ELK Stack (Elasticsearch, Logstash, Kibana) 이라고 널리 알려지게 된 Elastic은 2013년에 Logstash, Kibana 프로젝트를 정식으로 흡수하여 한 지붕 아래에서 함께 개발을 해 나가고 있습니다. 
* 2015년에는 회사명을 Elasticsearch 에서 Elastic으로 변경 하고, ELK Stack 대신 제품명을 Elastic Stack이라고 정식으로 명명하면서 모니터링, 클라우드 서비스, 머신러닝 등의 기능을 계속해서 개발, 확장 해 나가고 있습니다.

### Elasticsearch 

Elasticsearch는 Elastic Stack의 심장이다. 기본적으로 모든 데이터를 색인하여 저장하고 검색, 집계 등을 수행하며 결과를 클라이언트 또는 다른 프로그램으로 전달하여 동작하게 합니다.

  Elasticsearch는 뛰어난 검색 능력과 대규모 분산 시스템을 구축할 수 있는 다양한 기능들을 제공하지만, 설치 과정과 사용 방법은 비교적 쉽고 간편합니다.

기존 관계 데이터베이스 시스템에서는 다루기 어려운 전문검색(Full Text Search) 기능과 점수 기반의 다양한 정확도 알고리즘, 실시간 분석 등의 구현이 가능합니다.

#### 오픈소스

Apache 2.0 라이센스로 배포되고 있고 Elastic Stack의 모든 제품들은 (https://github.com/elastic) 깃헙 리파지토리 에서 소스들을 찾을 수 있습니다.

루씬이 자바로 만들어졌기 때문에 Elasticsearch도 마찬가지로 자바로 코딩이 되어 있습니다. 루씬은 하둡을 개발한 더그 커팅(Doug Cutting)에 의해 처음 만들어졌지만 Elasticsearch 엔지니어들 중에는 루씬 커미터들이 다수 있어서 루씬을 매우 깊은 레벨에서 다루고 있고, Elastic 사의 루씬 커미터인 개발자들이 실제로 루씬 프로젝트의 절반 이상의 기능을 개발에 기여하고 있습니다.

#### 실시간 분석

Elasticsearch의 가장 큰 특징 중 하나는 실시간(real-time) 분석 시스템 입니다.   Elasticsearch는 하둡 시스템과 달리 Elasticsearch 클러스터가 실행되고 있는 동안에는 계속해서 데이터가 입력 되고, 그와 동시에 실시간에 가까운 (near real-time) 속도로 색인된 데이터의 검색, 집계가 가능합니다.

#### 전문(full text) 검색 엔진

루씬은 기본적으로 역파일 색인(inverted file index)라는 구조로 데이터를 저장합니다. 루씬을 사용하고 있는 Elasticsearch도 마찬가지로 색인된 모든 데이터를 역파일 색인 구조로 저장하여 가공된 텍스트를 검색합니다.

이런 특성을 전문(full text) 검색이라고 합니다.

* JSON 문서 기반 Elasticsearch는 내부적으로는 역파일 색인 구조로 데이터를 저장하고 있으나, 
* 사용자의 관점에서는 JSON 형식으로 데이터를 전달합니다. 
* JSON형식은 간결하고 개발자들이 다루기 편한 구조로 되어 있어 색인 할 대상 문서를 가공 하거나 다른 클라이언트 프로그램과 연동하기에 용이합니다.
* 또한 key-value 형식이 아닌 문서 기반으로 되어 있기에 복합적인 정보를 포함하는 형식의 문서를 있는 그대로 저장이 가능하며 사용자가 직관적으로 이해하고 사용할 수 있습니다. 
* Elasticsearch에서 질의에 사용되는 쿼리문이나 쿼리에 대한 결과도 모두 JSON 형식으로 전달되고 리턴됩니다.
*  다만 JSON이 Elasticsearch가 지원하는 유일한 형식이기 사전에 입력할 데이터를 JSON 형식으로 가공하는 것이 필요합니다. CSV, Apache log, syslog등과 같이 널리 사용되는 형식들은 Logstash에서 변환을 지원하고 있습니다.



### Logstash

조던 시셀(Jordan Sissel)에 의해 탄생된 Logstash는 원래 Elasticsearch와 별개로 

* 데이터 수집과 저장을 위해 개발된 프로젝트
* Logstash가 출력 API로 Elasticsearch를 지원하기 시작하면서 많은 곳에서 Elasticsearch의 입력 수단 으로 Logstash를 사용
* Logstash는 JRuby로 되어 있습니다
* Apache 2.0 라이센스를 따르고 있어 자유롭게 사용이 가능합니다.

 Logstash는 데이터 처리를 위해서 크게 다음과 같은 과정들을 거치게 됩니다. : 입력, 필터, 출력



### Kibana

Elasticsearch는 Restful 한 속성과 JSON 문서 기반의 통신을 지원하기에 http 프로토콜을 이용해 어떤 클라이언트와도 손쉽게 연동이 가능합니다. 그래서 개발자들이 Elasticsearch와 연동되는 다양한 시각화 도구를 개발하였고, 이 중 라시드 칸(Rashid Khan)이 개발한 Kibana 라는 시각화 도구가 큰 인기를 끌었습니다.

  Kibana는 Elasticsearch를 가장 쉽게 시각화 할 수 있는 도구입니다. 검색, 그리고 aggregation의 집계 기능을 이용해 Elasticsearch로 부터 문서, 집계 결과 등을 불러와 웹 도구로 시각화를 합니다. 

#### Discover

Discover는 Elasticsearch에 색인된 소스 데이터들의 검색을 위한 메뉴입니다. 검색 창에 질의문을 통해 데이터를 간편하게 검색, 필터링 할 수 있으며, 검색된 데이터의 원본 문서를 확인하거나 보고 싶은 필드만 선택해서 테이블 형태로 조회가 가능합니다. 시계열(time series) 기반의 로그 데이터인 경우 시간 히스토그램 그래프를 통해 시간대별 로그 수도 표시됩니다.

#### Visualize

 Visualize는 aggregation 집계 기능을 통해 조회된 데이터의 통계를 다양한 차트로 표현할 수 있는 패널을 만드는 메뉴입니다. 영역차트, 바차트, 파이차트, 라인차트 등 다양한 시각화 도구들의 사용이 가능하며 여기서 만들어진 패널들을 조합해서 대시보드를 만들게 됩니다.

#### Dashboard

Visualize 메뉴에서 만들어진 시각화 도구들을 조합해서 대시보드 화면을 만들고 저장, 불러오기 등을 할 수 있는 메뉴입니다. 다른 메뉴들과 마찬가지로 검색 창에 쿼리를 입력하거나 시각화 도구들을 클릭해서 조회할 데이터들의 필터링이 가능하고, URL로 대시보드를 다른 사람들과 공유하거나 json 형식으로 내보내고 불러오기 등이 가능합니다

### Beats

독일에서 어느 두 개발자들이 Packetbeat라는 프로그램을 이용해 네트워크 패킷을 스니핑하여 Elasticsearch에 저장하여 모니터링 하는 시스템을 이용한 것, 개발 중이던 Logstash 원격 수집기 프로젝트는 중단되었고 그 역할을 Beats가 대신 실행하게 되었습니다.

#### 1. Metricbeat

  Metricbeat은 실행시켜놓기만 하면 시스템에서 실행중인 프로세스들의 정보와 이 프로세스들이 소모중인 CPU, Memory 등에 대한 상태들을 수집해서 Elasticsearch에 적재하고 손쉽게 이것들을 모니터링 할 수 있는 시스템을 만들 수 있습니다.

#### 2. Filebeat

  사용자들이 가장 필요로 하는 기능은 파일의 내용을 수집하는 기능입니다. Web log 또는 machine log 등이 저장되는 파일 경로를 지정하기만 하면 Filebeat은 해당 경로에 적재되는 파일을 읽어들이며 새로운 내용이 추가될 때 마다 그 내용을 Elasticsearch로 색인합니다.

#### 3. Libbeat

  먼저 Beats 팀은 처음 개발한 PacketBeat 프로그램에서 Elasticsearch로 전송하는 부분만을 따로 추출하여 일종의 공통 라이브러리로 만들었습니다. 특정한 데이터를 수집하는 부분만 코딩 하고 나면 데이터를 JSON 문서로 변환하고, 데이터가 유실되지 않게 관리하고, Elasticsearch로 전송하는 역할은 이 공통 라이브러리인 Libbeat이 담당하게 됩니다.

#### 4. Packetbeat

  가장 처음 존재했던 Beat이 바로 Packetbeat 입니다. 설치된 시스템에 유통되는 패킷들을 스니핑 해서 Elasticsearch에 적재시키는 기능을 합니다.

#### 5. Heartbeat

  다른 Beats 들도 이름에서 손쉽게 어떤 역할을 하는지 짐작이 가능한데, Heartbeat은 Beats 의 종류이면서도 심장 박동과 동일한 단어이기 때문에 재미있습니다. 역시 이름에서 유추할 수 있듯이 Heartbeat은 다른 프로세스들의 가동 시간 등을 모니터링 합니다. ICMP, TCP, HTTP 프로토콜 등을 통해 Ping 명령으로 원격의 프로세스의 가동 여부를 확인하는데, 동작은 단순하지만 다양한 시스템을 동시에 모니터링 할 때 매우 유용합니다.

#### 6. Functionbeat

  가장 최근에 추가된 Functionbeat은 요즘 유행하는 마이크로 서비스 아키텍쳐(MSA)와 같은 FaaS 클라우드 기반의 시스템에서 서버리스 프레임워크를 이용하여 클라우드 인프라를 모니터링 합니다. 다른 Beats 들과 달리 수집을 위한 데이터가 있는 시스템에 설치되는 것이 아니라 Lamda와 같은 기능으로 배포됩니다.



## 시작하기

### Downloads & install

#### 1. download

https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.0.0-linux-x86_64.tar.gz

https://www.elastic.co/kr/downloads/

```
$ sudo groupadd  elastic
$ sudo adduser  -g elastic elastic

$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.11.1-linux-x86_64.tar.gz
$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.0.0-linux-x86_64.tar.gz

$ wget https://artifacts.elastic.co/downloads/kibana/kibana-7.11.2-linux-x86_64.tar.gz
$ wget https://artifacts.elastic.co/downloads/kibana/kibana-8.0.0-linux-x86_64.tar.gz

$ tar xfz elasticsearch-7.11.1-linux-x86_64.tar.gz
$ tar xfz kibana-7.11.2-linux-x86_64.tar.gz
$ You can use the `bin/elasticsearch-reset-password` tool to set the password for the elastic user.
$ ~/bin/elasticsearch 
```

#### 2. 설정

* elasticsearch.yml 설정

 ~/config/elasticsearch.yml  편집

```sh
$ curl  -XGET http://localhost:9200
{
  "name" : "ubuntu20",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "3ubvZgKaQRCRnzhDC5A5oQ",
  "version" : {
    "number" : "7.11.1",
    "build_flavor" : "default",
    "build_type" : "tar",
    "build_hash" : "ff17057114c2199c9c1bbecc727003a907c0db7a",
    "build_date" : "2021-02-15T13:44:09.394032Z",
    "build_snapshot" : false,
    "lucene_version" : "8.7.0",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "You Know, for Search"
}
```

*  cluster, node name 변경

```
$ curl  -XGET http://localhost:9200
{
  "name" : "ubuntu20",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "3ubvZgKaQRCRnzhDC5A5oQ",
  "version" : {
    "number" : "7.11.1",
    "build_flavor" : "default",
    "build_type" : "tar",
    "build_hash" : "ff17057114c2199c9c1bbecc727003a907c0db7a",
    "build_date" : "2021-02-15T13:44:09.394032Z",
    "build_snapshot" : false,
    "lucene_version" : "8.7.0",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "You Know, for Search"
}

```



* kibana  :5601 port

```
$ ./kibana
...
  log   [13:40:17.648] [info][listening] Server running at http://localhost:5601
  log   [13:40:18.169] [info][server][Kibana][http] http server running at http://localhost:5601
^C  log   [13:41:06.397] [info][plugins-system] Stopping all plugins.
  log   [13:41:06.398] [info][kibana-monitoring][monitoring][monitoring][plugins] Monitoring stats collection is stopped


```



#### elasticsearch.service

```
root@ubuntu20:/etc/systemd/system# cat ./multi-user.target.wants/elasticsearch.service
[Unit]
Description=Elasticsearch
Documentation=https://www.elastic.co
Wants=network-online.target
After=network-online.target

[Service]
Type=notify
RuntimeDirectory=elasticsearch
PrivateTmp=true
Environment=ES_HOME=/usr/share/elasticsearch
Environment=ES_PATH_CONF=/etc/elasticsearch
Environment=PID_DIR=/var/run/elasticsearch
Environment=ES_SD_NOTIFY=true
EnvironmentFile=-/etc/default/elasticsearch
WorkingDirectory=/usr/share/elasticsearch
User=elasticsearch
Group=elasticsearch

ExecStart=/usr/share/elasticsearch/bin/systemd-entrypoint -p ${PID_DIR}/elasticsearch.pid --quiet

# StandardOutput is configured to redirect to journalctl since
# some error messages may be logged in standard output before
# elasticsearch logging system is initialized. Elasticsearch
# stores its logs in /var/log/elasticsearch and does not use
# journalctl by default. If you also want to enable journalctl
# logging, you can simply remove the "quiet" option from ExecStart.
StandardOutput=journal
StandardError=inherit
# Specifies the maximum file descriptor number that can be opened by this process
LimitNOFILE=65535
# Specifies the maximum number of processes
LimitNPROC=4096
# Specifies the maximum size of virtual memory
LimitAS=infinity
# Specifies the maximum file size
LimitFSIZE=infinity
# Disable timeout logic and wait until process is stopped
TimeoutStopSec=0
# SIGTERM signal is used to stop the Java process
KillSignal=SIGTERM
# Send the signal only to the JVM rather than its control group
KillMode=process
# Java process is never killed
SendSIGKILL=no
# When a JVM receives a SIGTERM signal it exits with code 143
SuccessExitStatus=143
# Allow a slow startup before the systemd notifier module kicks in to extend the timeout
TimeoutStartSec=75
[Install]
WantedBy=multi-user.target
# Built for packages-8.0.0 (packages)

```



### 클러스터 구조

####  cluster

![img](D:\Code\dev\img\cluster)



#### 인덱스와 샤드

Elasticsearch 에서는 단일 데이터 단위를 **도큐먼트(document)** 라고 하며 이 도큐먼트를 모아놓은 집합을 **인덱스(Index)** 라고 합니다. 인덱스라는 단어가 여러 뜻으로 사용되기 때문에 데이터 저장 단위인 인덱스는 **인디시즈(indices)** 라고 표현하기도 합니다. 

* 데이터를 Elasticsearch에 저장하는 행위는 **색인**, 
* 도큐먼트의 집합 단위는 **인덱스** 라고 하겠습니다.



```
$ curl -XPUT "http://localhost:9200/books" -H 'Content-Type: application/json' -d'
{
  "settings": {
    "number_of_shards": 5,
    "number_of_replicas": 1
  }
}'
```



```
$ curl -XGET http://localhost:9200/books
{"books":{"aliases":{},"mappings":{},"settings":{"index":{"routing":{"allocation":{"include":{"_tier_preference":"data_content"}}},"number_of_shards":"5","provided_name":"books","creation_date":"1646110042085","number_of_replicas":"1","uuid":"bL8m2PYkScGIXIsXSZ-lew","version":{"created":"7110199"}}}}}elastic@ubuntu20:~/els/config$ 
```







![img](D:\Code\dev\img\shard)



## REST API

#### RESTFul

- 입력 : `PUT http://user.com/kim -d {"name":"kim", "age":38, "gender":"m"}`
- 조회 : `GET http://user.com/kim`
- 삭제 : `DELETE http://user.com/kim`



#### kibana dev tools

* http://localhost:5601



### CRUD

  Elasticsearch에서는 단일 도큐먼트별로 고유한 URL을 갖습니다. 도큐먼트에 접근하는 URL은 

```
http://<호스트>:<포트>/<인덱스>/_doc/<도큐먼트 id> 
```

구조로 되어 있습니다. 

* curl로 해도 되지만  그래도 kibana dev tools를 사용하여 테스트 해본다. 

```sh
$ curl -XPUT "http://localhost:9200/my_index/_doc/1" -H 'Content-Type: application/json' -d'
{
  "name": "Jongmin Kim",
  "message": "안녕하세요 Elasticsearch"
}'
{"_index":"my_index","_type":"_doc","_id":"1","_version":1,"result":"created","_shards":{"total":2,"successful":1,"failed":0},"_seq_no":0,"_primary_term":1}
```



#### PUT

```json
PUT my_index/_doc/1
{
  "name":"Jongmin Kim",
  "message":"안녕하세요 Elasticsearch"
}
```

 처음으로 도큐먼트를 입력하면 결과에 `"result" : "created"` 로 표시가 됩니다. 동일한 URL에 다른 내용의 도큐먼트를 다시 입력하게 되면 기존 도큐먼트는 삭제되고 새로운 도큐먼트로 덮어씌워지게 됩니다. 이 때는 결과에 `created`가 아닌 `updated`가 표시됩니다.

* 결과

```json
{
  "_index" : "my_index",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 0,
  "_primary_term" : 1
}
```



#### GET

```json
GET my_index/_doc/1
```

* 결과

```
{
  "_index" : "my_index",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 3,
  "_seq_no" : 2,
  "_primary_term" : 1,
  "found" : true,
  "_source" : {
    "name" : "Jongmin Kim",
    "message" : "안녕하세요 Elasticsearch"
  }
}
```



#### POST

  POST 메서드는 PUT 메서드와 유사하게 데이터 입력에 사용이 가능합니다. 도큐먼트를 입력할 때 POST 메서드로 `<인덱스>/_doc` 까지만 입력하게 되면 자동으로 임의의 도큐먼트id 가 생성됩니다. 도큐먼트id의 자동 생성은 PUT 메서드로는 동작하지 않습니다.

```json
POST my_index/_doc
{
  "name":"Jongmin Kim",
  "message":"안녕하세요 Elasticsearch"
}
```



* 결과: id 값이 자동으로 생성된다. 

```json
{
  "_index" : "my_index",
  "_type" : "_doc",
  "_id" : "SGbvQ38BvWqIjT4Ix3FL",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 4,
  "_primary_term" : 1
}

```



* 오류: pretty=true

```
GET  my_index/_doc

{
  "error" : "Incorrect HTTP method for uri [/my_index/_doc?pretty=true] and method [GET], allowed: [POST]",
  "status" : 405
}
```



#### DELETE

```json
DELETE  my_index/_doc/2
```

* 결과

```json
{
  "_index" : "my_index",
  "_type" : "_doc",
  "_id" : "2",
  "_version" : 2,
  "result" : "deleted",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 5,
  "_primary_term" : 1
}
```



#### 벌크

```json
POST _bulk
{"index":{"_index":"test", "_id":"1"}}
{"field":"value one"}
{"index":{"_index":"test", "_id":"2"}}
{"field":"value two"}
{"delete":{"_index":"test", "_id":"2"}}
{"create":{"_index":"test", "_id":"3"}}
{"field":"value three"}
{"update":{"_index":"test", "_id":"1"}}
{"doc":{"field":"value two"}}
```

* PUT test/_doc/1 {"field": "value one"}
* PUT test/_doc/2 {"field":"value two"}
* DELETE test/_doc/2 
* PUT  test/_create/3  {"field":"value three"}
* PUT test/_doc/1  {"doc":{"field":"value two"}}



### 검색 API

Elasticsearch의 진가는 쿼리를 통한 검색 기능에 있습니다. 검색은 인덱스 단위로 이루어집니다. `GET <인덱스명>/_search` 형식으로 사용하며 쿼리를 입력하지 않으면 전체 도큐먼트를 찾는 **match_all** 검색을 합니다.

#### URI 검색

_search 뒤에 `q` 파라메터를 사용해서 검색어를 입력할 수 있습니다. 이렇게 요청 주소에 검색어를 넣어 검색하는 방식을 **URI 검색**이라고 합니다. 

``` json
GET test/_search?q=value
```

* 결과: field의 값이 "value"에 해당하는 값 2건이 hits되어 조회 된다. 

```json
{
  "took" : 1,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 2,
      "relation" : "eq"
    },
    "max_score" : 0.10536051,
    "hits" : [
      {
        "_index" : "test",
        "_type" : "_doc",
        "_id" : "3",
        "_score" : 0.10536051,
        "_source" : {
          "field" : "value three"
        }
      },
      {
        "_index" : "test",
        "_type" : "_doc",
        "_id" : "1",
        "_score" : 0.10536051,
        "_source" : {
          "field" : "value two"
        }
      }
    ]
  }
}

```



#### body data 검색

``` json
GET test/_search
{
  "query": {
    "match": {
      "field": "value"
    }
  }
}
```



* 결과

```json
{
  "took" : 1,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 2,
      "relation" : "eq"
    },
    "max_score" : 0.10536051,
    "hits" : [
      {
        "_index" : "test",
        "_type" : "_doc",
        "_id" : "3",
        "_score" : 0.10536051,
        "_source" : {
          "field" : "value three"
        }
      },
      {
        "_index" : "test",
        "_type" : "_doc",
        "_id" : "1",
        "_score" : 0.10536051,
        "_source" : {
          "field" : "value two"
        }
      }
    ]
  }
}
```



## Full Text Query

* data 입력

```json
POST my_index/_bulk
{"index":{"_id":1}}
{"message":"The quick brown fox"}
{"index":{"_id":2}}
{"message":"The quick brown fox jumps over the lazy dog"}
{"index":{"_id":3}}
{"message":"The quick brown fox jumps over the quick dog"}
{"index":{"_id":4}}
{"message":"Brown fox brown dog"}
{"index":{"_id":5}}
{"message":"Lazy jumping dog"}
```



#### match_all

```json
GET my_index/_search
```



#### match

```json
GET my_index/_search
{
  "query": {
    "match": {
      "message": "dog"
    }
  }
}
```



* or 조건:  quick or dog 조건으로 검색

```json
GET my_index/_search
{
  "query": {
    "match": {
      "message": "quick dog"
    }
  }
}
```

* and 조건 : quick and dog 조건으로 검색

```json
GET my_index/_search
{
  "query": {
    "match": {
      "message": {
        "query": "quick dog",
        "operator": "and"
      }
    }
  }
}
```



#### 복합 Query

* must : 쿼리가 참인 도큐먼트들을 검색합니다. 

* must_not : 쿼리가 거짓인 도큐먼트들을 검색합니다. 

* should : 검색 결과 중 이 쿼리에 해당하는 도큐먼트의 점수를 높입니다. 

* filter : 쿼리가 참인 도큐먼트를 검색하지만 스코어를 계산하지 않습니다. must 보다 검색 속도가 빠르고 캐싱이 가능합니다.

```json
GET <인덱스명>/_search
{
  "query": {
    "bool": {
      "must": [
        { <쿼리> }, …
      ],
      "must_not": [
        { <쿼리> }, …
      ],
      "should": [
        { <쿼리> }, …
      ],
      "filter": [
        { <쿼리> }, …
      ]
    }
  }
}
```



#### 범위 Query

```json
POST phones/_bulk
{"index":{"_id":1}}
{"model":"Samsung GalaxyS 5","price":475,"date":"2014-02-24"}
{"index":{"_id":2}}
{"model":"Samsung GalaxyS 6","price":795,"date":"2015-03-15"}
{"index":{"_id":3}}
{"model":"Samsung GalaxyS 7","price":859,"date":"2016-02-21"}
{"index":{"_id":4}}
{"model":"Samsung GalaxyS 8","price":959,"date":"2017-03-29"}
{"index":{"_id":5}}
{"model":"Samsung GalaxyS 9","price":1059,"date":"2018-02-25"}
```



range 쿼리는 `range : { <필드명>: { <파라메터>:<값> } }` 으로 입력됩니다. range 쿼리 파라메터는 아래의 4가지가 있습니다. 

- gte :  (Greater-than or equal to) - 이상 (같거나 큼)
- gt : (Greater-than) – 초과 (큼)
- lte :  (Less-than or equal to) - 이하 (같거나 작음)
- lt :  (Less-than) - 미만 (작음)



```json
GET phones/_search
{
  "query": {
    "range": {
      "price": {
        "gte": 700,
        "lt": 900
      }
    }
  }
}
```



#### 날짜 검색

```json
GET phones/_search
{
  "query": {
    "range": {
      "date": {
        "gt": "2016-01-01"
      }
    }
  }
}
```



